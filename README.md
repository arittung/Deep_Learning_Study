# 딥러닝 스터디

https://velog.io/@arittung/series/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%8A%A4%ED%84%B0%EB%94%94

위 링크에 작성된 내용에 기반한 코드.<br><br><br>

## 목차
- [1. Day01](#Day01)
  - [인공지능과 머신러닝, 딥러닝이란?](#인공지능과-머신러닝,-딥러닝이란?)
  - [퍼셉트론](#퍼셉트론)
- [2. Day02](#Day02)
  - [지도 학습과 비지도 학습, 강화 학습](#지도-학습과-비지도-학습-강화-학습)
  - [k-최근접 이웃 알고리즘(K-Nearest Neighbor)](#k-최근접-이웃-알고리즘(K-Nearest-Neighbor))
- [3. Day03](#Day03)
  - [데이터 전처리](#데이터-전처리)
  - [Day03.pynb에 대한 설명](#day03pynb에-대한-설명)
- [4. Day04](#Day04)
  - [k-최근접 이웃 회귀 (KNN-Regression)](#k-최근접-이웃-회귀-knn-regression)
- [5. Day05](#Day05)
  - [선형 회귀 (Linear-Regression)](#선형-회귀-linear-regression)
- [6. Day06](#Day06)
  - [다중 회귀 (Multiple-Regression)](#다중-회귀-multiple-regression)
  - [특성 공학 (Feature Engineering)](#특성-공학-feature-engineering)
  - [판다스 (Pandas)](#판다스-pandas)
  - [규제 (Regularization)](#규제-regularization)
- [7. Day07](#Day07)
  - [다중 분류 (Multi-Class Classification)](#다중-분류-multi-class-classification)
  - [로지스틱 회귀 (Logistic Regression)](#로지스틱-회귀-logistic-regression)
  - [시그모이드 함수와 소프트맥스 함수](#시그모이드-함수와-소프트맥스-함수)


<Br>
<br>

---

<br>

## Day01
#### 인공지능과 머신러닝, 딥러닝이란?
  - 인공지능
  - 머신러닝
  - 딥러닝
 
#### 퍼셉트론
  - 퍼셉트론
  - 단층 퍼셉트론
  - 단층 퍼셉트론 구현 코드
  - 다층 퍼셉트론(MLP, Multi-Layer Perceptron)

<br>

## Day02
#### 지도 학습과 비지도 학습, 강화 학습
  - 지도 학습(Supervised Learning)
    - 분류(Classification)
    - 회귀(Regression)
  - 비지도 학습(unsupervised learning)
  - 강화 학습(Reinforcement Learning)
 
#### k-최근접 이웃 알고리즘(K-Nearest Neighbor)
  - KNN 구현 코드

<br>

## Day03
#### 데이터 전처리
  - 전처리 과정에서 해야 하는 일
  - 주요 데이터 전처리 기법
#### Day03.pynb에 대한 설명
  - 전처리 전
  - 전처리 후

<br>


## Day04
#### k-최근접 이웃 회귀 (KNN-Regression)
  - 결정 계수 (Coefficient of determination, R^2)
  - 과대적합(Overfitting) & 과소적합(Underfitting)
    - 과대 적합(Overfitting)
    - 과소 적합(Underfitting)
  - KNN-Regression 구현 코드

 <br>


## Day05
#### 선형 회귀 (Linear-Regression)
  - 손실(Loss)
    - 평균 제곱 오차(MSE, Mean Squared Error)
    - 평균 절대 오차(MAE, Mean Absolute Error)
  - 경사 하강법 (Gradient Descent)
  - 수렴(Convergence)
  - 과소 적합(Underfitting)
  - 학습률 (Learning Rate)
  - 다항 회귀 (Polynomial Regression)
  - 구현 코드

 <br>


## Day06
#### 다중 회귀 (Multiple Regression)
#### 특성 공학 (Feature Engineering)
#### 판다스 (Pandas)
#### 규제 (Regularization)
  - 규제의 필요성
  - 릿지 회귀 (Ridge Regression)와 라쏘 회귀 (Lasso Regression), 엘라스틱 넷 회귀 (ElasticNet Regression)
    - 릿지 회귀
    - 라쏘 회귀
    - 엘라스틱 넷 회귀

 <br>

## Day07
#### 다중 분류 (Multi-Class Classification)
#### 로지스틱 회귀 (Logistic Regression)
#### 시그모이드 함수와 소프트맥스 함수
  - 시그모이드 함수 (Sigmoid Function, 로지스틱 함수(Logistic Function))
  - 소프트맥스 함수(SoftMax Function)



<br><br>
---
<br>

## 참고 도서
<img src="https://images.velog.io/images/arittung/post/de70472d-133c-44cb-b17f-a66d9fada811/image.png" width="150px">

**[한빛미디어] 혼자 공부하는 머신러닝+딥러닝, 박해선 저**


