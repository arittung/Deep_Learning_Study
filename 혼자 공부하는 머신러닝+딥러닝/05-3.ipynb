{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f5QBQGBJCWD"
      },
      "source": [
        "## 05-3 트리의 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzn13CppJUqy"
      },
      "source": [
        "### 랜덤 포레스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jloG4lmAJWD3",
        "outputId": "a2abc478-12c0-41e7-9ffc-c3cf0cb38208"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "# 와인 데이터셋을 판다스로 불러오고 훈련 세트와 테스트 세트로 나눔.\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier()\n",
        "# : 기본적으로 전체 특성 개수의 제곱근만큼의 특성 선택 / 4개의 특성이 있다면 노드마다 2개를 랜덤하게 선택하여 사용.\n",
        "# : 기본적으로 100개의 결정 트리를 사용하므로 n_jobs = -1로 지정하여 모든 CPU 코어를 사용하는 것이 좋음.\n",
        "# : 자체적으로 모델을 평가하는 점수 얻을 수 있음.\n",
        "# RandomForestRegressor() : 전체 특성 사용.\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "# cross_validate() : 교차 검증 수행\n",
        "# n_jobs = -1로 지정하여 최대한 병렬로 교차 검증 수행.\n",
        "#  return_train_score=True로 지정(기본값 : False)하여 검증 점수 뿐 아니라 훈련 세트에 대한 점수까지 반환. 훈련 세트와 검증 세트의 점수를 비교하면 과대적합을 파악하는데 용이.\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 훈련 세트에 다소 과대적합.\n",
        "\n",
        "\n",
        "# 랜덤 포레스트는 결정 트리의 앙상블이기 때문에 DecisionTreeClassfier가 제공하는 중요한 매개변수를 모두 제공.(결정 트리의 큰 장점 중 하나인 특성 중요도 계산)\n",
        "# 랜덤 포레스트의 특성 중요도 == 각 결정 트리의 특성 중요도를 취합한 것.\n",
        "\n",
        "# 랜덤 포레스트 모델을 훈련 세트에 훈련한 후 특성 중요도 출력\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)\n",
        "# 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻음.\n",
        "# 이는 과대적합을 줄이고 일반화 성능을 높이는데 도움을 줌.\n",
        "\n",
        "# oob_score=True : 각 결정 트리의 OOB 점수를 평균하여 출력\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)\n",
        "# 교차 검증에서 얻은 점수와 비슷한 결과."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9973541965122431 0.8905151032797809\n",
            "[0.23167441 0.50039841 0.26792718]\n",
            "0.8934000384837406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUVk_trdMdtE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02F1WXU_w5QN"
      },
      "source": [
        "## 엑스트라 트리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESghlCYhw62f",
        "outputId": "0b900b8d-be58-44ab-ecb8-846b0beda436"
      },
      "source": [
        "# ExtraTreesClassifier() : 사이킷런에서 제공하는 엑스트라 트리\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 랜덤 포레스트와 비슷한 결과.\n",
        "\n",
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)\n",
        "# 특성 중요도 제공\n",
        "#[알코올 도수, 당도, ph]\n",
        "# 엑스트라 트리도 결정 트리보다 당도에 대한 의존성이 작음."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9974503966084433 0.8887848893166506\n",
            "[0.20183568 0.52242907 0.27573525]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlX-I1kKyBFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahXA4j0Syji9"
      },
      "source": [
        "## 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxeuBvcyylwg",
        "outputId": "d844b865-779c-477a-bab4-2296302496bc"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 거의 과대적합 되지 않음.\n",
        "\n",
        "# n_estimators=500 : 결정 트리 개수를 500개로 설정\n",
        "# learning_rate 기본값 = 0.1\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 결정 트리 개수를 5배나 늘렸지만 과대적합 잘 억제하고 있음.\n",
        "\n",
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)\n",
        "# 특성 중요도\n",
        "# 랜덤 포레스트 보다 당도에 더 집중."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8881086892152563 0.8720430147331015\n",
            "0.9464595437171814 0.8780082549788999\n",
            "[0.15872278 0.68010884 0.16116839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcHV3l3zUPB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnp7zXz2kVd"
      },
      "source": [
        "## 히스토그램 기반 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVUzNqpx2mjT",
        "outputId": "61de390c-6cd5-4591-bb86-0fe06128f67e"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "# HistGradientBoostingClassifier \n",
        "# : 사이킷런의 히스토그램 기반 그레이디언트 부스팅 클래스, 기본 매개변수에서 안정적인 성능을 얻을 수 있음.\n",
        "# : 트리 개수 지정시 부스팅 반복 횟수 지정하는 max_iter 사용.\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 과대적합을 잘 억제하면서 그레이디언트 부스팅보다 조금 더 높은 성능 제공\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "# permutation_importance()\n",
        "# : 히스토그램 기반 그레이디언트 부스팅의 특성 중요도 계산\n",
        "# : 특성을 하나씩 랜덤하게 섞어 모델의 성능이 변화하는지를 관찰하여 어떤 특성이 중요한지 계산\n",
        "# : 훈련 세트 뿐 아니라 테스트 세트에도 적용가능, 사이킷런에서 제공하는 추정기 모델에 모두 사용가능.\n",
        "# : 리턴하는 객체는 반복하여 얻은 특성 중요도(importance), 평균 (importance_mean), 표준편차(importances_std)를 담고 있음.\n",
        "# n_repeats : 랜덤하게 섞을 횟수 지정.\n",
        "\n",
        "# 훈련 세트에서 특성 중요도 계산\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)\n",
        "# 평균 출력 : 랜덤 포레스트와 비슷한 비율\n",
        "\n",
        "# 테스트 세트에서 특성 중요도 계산\n",
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)\n",
        "# 그레디언트 부스팅과 비슷하게 조금 더 당도에 집중\n",
        "\n",
        "# 테스트 세트에서의 성능 최종 확인\n",
        "hgb.score(test_input, test_target)\n",
        "# 약 87%의 정확도\n",
        "# 앙상블 모델이 단일 결정 모델보다 좋은 결과 얻음."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9321723946453317 0.8801241948619236\n",
            "[0.08876275 0.23438522 0.08027708]\n",
            "[0.05969231 0.20238462 0.049     ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXzEsItU3BB4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88tiWcneMLiV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_sprJ5o4xyI"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUN00w4N403U"
      },
      "source": [
        "### 사이킷런 이외에 히스토그램 기반 그레이디언트 부스팅 알고리즘 구현한 라이브러리 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxs2jap946bw",
        "outputId": "d6662f84-66f8-43f4-8075-1e3f83ae8e77"
      },
      "source": [
        "# XGBoost 사용해 와인 데이터의 교차 검증 점수 확인.\n",
        "rom xgboost import XGBClassifier\n",
        "\n",
        "# tree_method='hist' : 히스토그램 기반 그레이디언트 부스팅 사용가능.\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8824322471423747 0.8726214185237284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbM34Lvg5QbB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBSF0kGT4-NC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9UkIb3b5L8V"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITpNiOhT5LSb"
      },
      "source": [
        "### 사이킷런 이외에 히스토그램 기반 그레이디언트 부스팅 알고리즘 구현한 라이브러리 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wi3RkwG45om",
        "outputId": "e0d7432e-bda1-4831-ebde-46b7f2e9e70d"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9338079582727165 0.8789710890649293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6hcuBTN5T3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvXLzhkH4zzM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c4ERgmkLG2N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nje4AddJfcu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0HVRMKLJFGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4WCEG0bJA2H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
